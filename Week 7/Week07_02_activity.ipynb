{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44df5f05-aa79-4f4b-bac7-0b441fd10934",
   "metadata": {},
   "source": [
    "<style>\n",
    "body h1:before, body h2:before, body h3:before, body h4:before, body h5:before, body h6:before {\n",
    "  content: \"\";\n",
    "  counter-increment: none;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8281eb25-292a-4f5c-9a6d-4360815466a8",
   "metadata": {},
   "source": [
    "\\setcounter{secnumdepth}{0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17474efc-a435-431c-87b6-abcee356b403",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Week07.2 Team Activity\n",
    "Due Thursday May 18th, 2023 by 11:59pm - please upload PDF with photograph (either rendered or a separate file).  There is no expectation of completing this during class, in fact, I am trying to get you to practice working outside of class in teams in preparation for the final project.\n",
    "\n",
    "If you missed class â€“ no credit for this activity, instead, I drop two unexcused absences from the Monday/Wednesday activities before deductions begin.\n",
    "\n",
    "- **Please identify your team & the names of your teammates.** \n",
    "\n",
    "- **Please insert a team photo somewhere in this notebook.  If you cannot get the to render correctly to PDF please upload a separate file of the photo**\n",
    "\n",
    "- **Please make certain that all of your teammates agree upon and understand the team answers. Thank you.**\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3e77780",
   "metadata": {},
   "source": [
    "Names: Blair L, Aryan S, Ryan T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5818b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\".jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc9cc52-6082-43f0-83b2-87af0ee48bd4",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab116103-ef06-4ad0-8c10-bc58d1191103",
   "metadata": {},
   "source": [
    "As always, what is important is a team effort and that everyone on the team has an idea of how to program these things and also feels free to ask the team for more understanding.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eec6496-0112-4826-91a4-3bd0ad843ebf",
   "metadata": {},
   "source": [
    "Because we are in the process of forming final teams, if you are having trouble coming together as a team to complete an assignment like this one,  you should look for a different team for the next activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9756273-9510-4781-8323-84d073f82c21",
   "metadata": {},
   "source": [
    "## Mash-Up Maybe...\n",
    "\n",
    "Today's team activity involves using some things we've learned about in the past (strings, removing duplicates) and from Numpy today (creating matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d54719a-5fb2-49b5-a6f5-1ae6e737f298",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im findin ways to articulate the feelin im goin through\n",
      "i just cant say i dont love you yeah\n",
      "cause i love you yeah\n",
      "its hard for me to communicate the thoughts that i hold\n",
      "but tonight im gon let you know\n",
      "let me tell the truth\n",
      "baby let me tell the truth yea\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "url = 'http://www.stat.ucla.edu/~vlew/datasets/die_for_you.txt'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# .text is a property of the Response object\n",
    "# .lower is a string method\n",
    "ex_text = response.text.lower()\n",
    "\n",
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "# please remove the punctuation as seen in punc\n",
    "no_punc = []\n",
    "no_punc_ex_text = []\n",
    "for letter in ex_text:\n",
    "    if letter not in punc:\n",
    "        no_punc.append(letter)\n",
    "        no_punc_ex_text = \"\".join(no_punc)\n",
    "ex_text = no_punc_ex_text\n",
    " \n",
    "print(ex_text[0:255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03f83826-04c8-41dd-831a-4782008691c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['im', 'findin', 'ways', 'to', 'articulate', 'the', 'feelin', 'goin', 'through', 'i', 'just', 'cant', 'say', 'dont', 'love', 'you', 'yeah', 'cause', 'its', 'hard', 'for', 'me', 'communicate', 'thoughts', 'that', 'hold', 'but', 'tonight', 'gon', 'let', 'know', 'tell', 'truth', 'baby', 'what', 'thinkin', 'see', 'it', 'in', 'your', 'eyes', 'hate', 'want', 'when', 'cry', 'youre', 'scared', 'be', 'lonely', 'specially', 'night', 'ill', 'miss', 'happens', 'every', 'time', 'this', 'afford', 'try', 'find', 'a', 'reason', 'pull', 'us', 'apart', 'aint', 'workin', 'perfect', 'and', 'worth', 'walk', 'away', 'oh', 'even', 'though', 'were', 'makes', 'feel', 'alone', 'would', 'die', 'distance', 'between', 'itll', 'never', 'change', 'my', 'mind', 'manipulate', 'girl', 'not', 'blamin', 'blame', 'too', 'take', 'pain', 'forever', 'wont', 'no', 'one', 'thats', 'better', 'right', 'babe', 'think', 'uh', 'lie', 'keep', 'real', 'with', 'kill', 'sayin', 'nanana']\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "# split ex_text into separate words save as a list (you will need this later)\n",
    "words = ex_text.split()\n",
    "\n",
    "# remove the duplicate words (heard that before?) save as a different list\n",
    "vocab = []\n",
    "for word in words:\n",
    "    if word not in vocab:\n",
    "        vocab.append(word)\n",
    "\n",
    "print(vocab)\n",
    "\n",
    "# check the length of the non duplicated word list\n",
    "print(len(vocab))\n",
    "# 113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9eef3959-eb6b-481b-8a79-3bce08d0da02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# create a square matrix of zeros using the length of \n",
    "# the non-duplicated words for the length of rows, cols\n",
    "matrix = np.zeros((len(vocab), len(vocab)))\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fcc00935-5f74-4151-ad67-4944fffcc305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 113)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the .shape attribute to show it's correct\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea888008-3ac4-41dc-a881-5dd2814b292b",
   "metadata": {},
   "source": [
    "## The Next Step\n",
    "\n",
    "(programmed for you) A transition matrix (typically used for Markov Chains) serving as a small step to illustrate some of the concepts involved in Large Language Models.\n",
    "\n",
    "If you think of each unique word in any text as a \"state\", a Markov Chain can generate text by starting at a certain word and then randomly choosing the next word based on the probabilities in the transition matrix.\n",
    "\n",
    "This is much simpler than a language model, especially like ChatGPT. Models like that not only look at the next word, but it also looks at the context of a sentence or a paragraph to predict the next word or to generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d266c40e-5fa2-4082-b5a8-6d6f88a691a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.18181818, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.66666667]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill the matrix with transition probabilities\n",
    "# did it for you, feel free to correct any errors...\n",
    "# assuming your duplicated list of words without punctuation is named words\n",
    "# assuming your non-duplicated version is named vocab\n",
    "\n",
    "for i in range(len(words) - 1):\n",
    "    current_word = words[i]\n",
    "    next_word = words[i + 1]\n",
    "\n",
    "    current_index = vocab.index(current_word)\n",
    "    next_index = vocab.index(next_word)\n",
    "\n",
    "    matrix[current_index][next_index] += 1\n",
    "\n",
    "# normalize the matrix rows to sum to 1\n",
    "row_sums = matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Avoid division by zero\n",
    "matrix = np.where(row_sums != 0, matrix / row_sums, matrix)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39427353-1d7f-4904-ba90-24569db9d78d",
   "metadata": {},
   "source": [
    "## Try it out\n",
    "\n",
    "If everything is working, generated_text should be a random word from vocab (which is your non-duplicated word list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7646ac54-1e07-4d7d-9602-773d3b351a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tell']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assuming your non-duplicated list of words is named vocab\n",
    "# generate text\n",
    "generated_text = [np.random.choice(vocab)]\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f8c819-7369-4911-bc63-10d6b2dc21be",
   "metadata": {},
   "source": [
    "# Choose an integer for num_words\n",
    "\n",
    "This is the length of the string you wish to generate. These words are generated probabilistically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17325d3a-b867-4865-8c8b-c5ef35399bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tell the distance and the time between us apart it\n"
     ]
    }
   ],
   "source": [
    "num_words = 9\n",
    "\n",
    "for i in range(num_words):\n",
    "    last_word = generated_text[-1]\n",
    "    last_index = vocab.index(last_word)\n",
    "\n",
    "    next_word = np.random.choice(vocab, p=matrix[last_index])\n",
    "    generated_text.append(next_word)\n",
    "\n",
    "print(\" \".join(generated_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d34b3a1-1ddb-493b-99b8-c98205b4d9c1",
   "metadata": {},
   "source": [
    "## What to submit for credit\n",
    "\n",
    "- Please upload the Jupyter Notebook (.ipynb) and PDF (preferred) OR .html (OK) to Bruin Learn with your team attempt.  Please make sure every team member understands the contents of the notebook.  \n",
    "\n",
    "- This is due before 11:59pm Thursday 5/18/2023 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
