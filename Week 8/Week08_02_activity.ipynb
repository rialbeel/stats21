{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44df5f05-aa79-4f4b-bac7-0b441fd10934",
   "metadata": {},
   "source": [
    "<style>\n",
    "body h1:before, body h2:before, body h3:before, body h4:before, body h5:before, body h6:before {\n",
    "  content: \"\";\n",
    "  counter-increment: none;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8281eb25-292a-4f5c-9a6d-4360815466a8",
   "metadata": {},
   "source": [
    "\\setcounter{secnumdepth}{0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17474efc-a435-431c-87b6-abcee356b403",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Week08.2 Team Activity\n",
    "Due Thursday May 25th, 2023 by 11:59pm - please upload PDF with photograph (either rendered or a separate file).  There is no expectation of completing this during class, in fact, I am trying to get you to practice working outside of class in teams in preparation for the final project.\n",
    "\n",
    "If you missed class â€“ no credit for this activity, instead, I drop two unexcused absences from the Monday/Wednesday activities before deductions begin.\n",
    "\n",
    "- **Please identify your team & the names of your teammates.** \n",
    "\n",
    "- **Please insert a team photo somewhere in this notebook.  If you cannot get the to render correctly to PDF please upload a separate file of the photo**\n",
    "\n",
    "- **Please make certain that all of your teammates agree upon and understand the team answers. Thank you.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb3153-7c1f-4af7-95f3-96f8d22bdfcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Assignment\n",
    "\n",
    "If you are with your final project team and have your data, please go ahead and use your final data for this activity.\n",
    "\n",
    "If you are not on a team or sitting with non-teammates today, please try the following, this is a random forest with numerical outcome (price) I've done the preparation for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d89242b0-dd7a-481a-95ce-042172f294bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File train.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestClassifier, RandomForestRegressor\n\u001b[0;32m----> 7\u001b[0m train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(\u001b[39m\"\u001b[39;49m\u001b[39mtrain.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m train\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39mbuilding_id\u001b[39m\u001b[39m'\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m train\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/json/_json.py:733\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39mif\u001b[39;00m convert_axes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m orient \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    731\u001b[0m     convert_axes \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m json_reader \u001b[39m=\u001b[39m JsonReader(\n\u001b[1;32m    734\u001b[0m     path_or_buf,\n\u001b[1;32m    735\u001b[0m     orient\u001b[39m=\u001b[39;49morient,\n\u001b[1;32m    736\u001b[0m     typ\u001b[39m=\u001b[39;49mtyp,\n\u001b[1;32m    737\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    738\u001b[0m     convert_axes\u001b[39m=\u001b[39;49mconvert_axes,\n\u001b[1;32m    739\u001b[0m     convert_dates\u001b[39m=\u001b[39;49mconvert_dates,\n\u001b[1;32m    740\u001b[0m     keep_default_dates\u001b[39m=\u001b[39;49mkeep_default_dates,\n\u001b[1;32m    741\u001b[0m     numpy\u001b[39m=\u001b[39;49mnumpy,\n\u001b[1;32m    742\u001b[0m     precise_float\u001b[39m=\u001b[39;49mprecise_float,\n\u001b[1;32m    743\u001b[0m     date_unit\u001b[39m=\u001b[39;49mdate_unit,\n\u001b[1;32m    744\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    745\u001b[0m     lines\u001b[39m=\u001b[39;49mlines,\n\u001b[1;32m    746\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    747\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    748\u001b[0m     nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[1;32m    749\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    750\u001b[0m     encoding_errors\u001b[39m=\u001b[39;49mencoding_errors,\n\u001b[1;32m    751\u001b[0m )\n\u001b[1;32m    753\u001b[0m \u001b[39mif\u001b[39;00m chunksize:\n\u001b[1;32m    754\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/json/_json.py:818\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlines:\n\u001b[1;32m    816\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnrows can only be passed if lines=True\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 818\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data_from_filepath(filepath_or_buffer)\n\u001b[1;32m    819\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/json/_json.py:874\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    866\u001b[0m     filepath_or_buffer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n\u001b[1;32m    867\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[1;32m    868\u001b[0m     \u001b[39misinstance\u001b[39m(filepath_or_buffer, \u001b[39mstr\u001b[39m)\n\u001b[1;32m    869\u001b[0m     \u001b[39mand\u001b[39;00m filepath_or_buffer\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mendswith(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[1;32m    873\u001b[0m ):\n\u001b[0;32m--> 874\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{\u001b[39;00mfilepath_or_buffer\u001b[39m}\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    876\u001b[0m \u001b[39mreturn\u001b[39;00m filepath_or_buffer\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File train.json does not exist"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "train = pd.read_json(\"train.json\")\n",
    "train.set_index('building_id', inplace=True)\n",
    "train.head()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82d02d4-d60e-4fee-93d0-5d9533fc11a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# turn the outcome into categories\n",
    "train['interest_level'] =  pd.Categorical(\n",
    "    train['interest_level'], \n",
    "    categories=[\"low\", \"medium\", \"high\"], ordered=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b9d0f7-a129-4bf2-a89c-0310cf35ceac",
   "metadata": {},
   "source": [
    "## Add additional features to this list\n",
    "\n",
    "Please add additional features to the model.  I've only included location (lon/lat) but there are others.  I didn't talk about RandomForestRegressor (numerical outcome) so here is the model (followed by an explanation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e35aa-0a2c-466e-b3d7-03e4c0c6b3db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = ['longitude', 'latitude', 'price']\n",
    "train_sub = train[feature_names]\n",
    "X_train, y_train = train_sub.drop('price',axis=1), train_sub['price']\n",
    "rf = RandomForestRegressor(\n",
    "         n_estimators=100,\n",
    "         min_samples_leaf=1,\n",
    "         n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e8c81-c586-4f93-b6b5-a0d4df47eb07",
   "metadata": {},
   "source": [
    "n_estimators: This is the number of trees in the forest. In this case, 100 trees will be estimated.\n",
    "\n",
    "min_samples_leaf: This is the minimum number of samples required to be at a leaf node. The algorithm won't allow a split that leaves fewer than this number of samples in a node.\n",
    "\n",
    "n_jobs: The number of jobs to run in parallel for both fit and predict. If -1, then the number of jobs is set to the number of cores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccd5bd9-cc8a-46c9-b1a4-85be9b6c7ab2",
   "metadata": {},
   "source": [
    "## Fit your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881cc3c5-aa3a-4bdf-9e49-f48ed156ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db92aa3-6c32-4233-80eb-334405bdfe74",
   "metadata": {},
   "source": [
    "## Examine the results\n",
    "\n",
    "Example, check the feature importance (you should add more variables and modify the graphic) and what do you conclude about the real estate features and price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53774b22-0485-4f6c-b168-ca3970b407c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_importance = rf.feature_importances_[0:2]\n",
    "indices = np.argsort(feature_importance)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Feature importance\")\n",
    "plt.barh(range(len(indices)), feature_importance[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b334525-bca2-4828-a449-805b26bf3333",
   "metadata": {},
   "source": [
    "There are more things you could do, for example, predict price using the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef69a93c-8bf7-4416-9395-350e36b74acc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "3.  Can your team modify this model to examine the categorical outcome \"interest_level\"?  If yes, how does the model for interest_level differ from price with respect to variables like location and the features of the rental unit.\n",
    "\n",
    "Please remember to take a team photo.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d34b3a1-1ddb-493b-99b8-c98205b4d9c1",
   "metadata": {},
   "source": [
    "## What to submit for credit\n",
    "\n",
    "- Please upload the Jupyter Notebook (.ipynb) and PDF (preferred) OR .html (OK) to Bruin Learn with your team attempt.  Please make sure every team member understands the contents of the notebook.  \n",
    "\n",
    "- This is due before 11:59pm Thursday 5/25/2023 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
